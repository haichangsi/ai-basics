{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(ABC):\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size) * np.sqrt(\n",
    "            2.0 / input_size\n",
    "        )\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.weights @ self.input + self.bias\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = output_gradient @ self.input.T\n",
    "        input_gradient = self.weights.T @ output_gradient\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient\n",
    "\n",
    "\n",
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient * self.activation_prime(self.input)\n",
    "\n",
    "\n",
    "class ReLU(Activation):\n",
    "    def __init__(self):\n",
    "        relu = lambda x: np.maximum(x, 0)\n",
    "        relu_prime = lambda x: (x > 0).astype(int)\n",
    "        super().__init__(relu, relu_prime)\n",
    "\n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        sigmoid_prime = lambda x: sigmoid(x) * (1 - sigmoid(x))\n",
    "        super().__init__(sigmoid, sigmoid_prime)\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input_shape = input.shape\n",
    "        return input.flatten().reshape(-1, 1)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_digits(return_X_y=True)\n",
    "x_train, y_train = x[:1500], y[:1500]\n",
    "x_test, y_test = x[1500:], y[1500:]\n",
    "\n",
    "# normalize - grayscale values for a pixel are between 0 and 16 for this dataset\n",
    "x_train = x_train / 16\n",
    "x_test = x_test / 16\n",
    "\n",
    "# one-hot\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "# network\n",
    "network = [Flatten(), Dense(64, 128), ReLU(), Dense(128, 10), Sigmoid()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Error: 0.06779940675814822\n",
      "Epoch 2/50 - Error: 0.03266676038573149\n",
      "Epoch 3/50 - Error: 0.02140012667395678\n",
      "Epoch 4/50 - Error: 0.01619576374164077\n",
      "Epoch 5/50 - Error: 0.01340168269711138\n",
      "Epoch 6/50 - Error: 0.011668946889499269\n",
      "Epoch 7/50 - Error: 0.010475968410768753\n",
      "Epoch 8/50 - Error: 0.009590737088822838\n",
      "Epoch 9/50 - Error: 0.008898237467366968\n",
      "Epoch 10/50 - Error: 0.008345441544034821\n",
      "Epoch 11/50 - Error: 0.007883617077136622\n",
      "Epoch 12/50 - Error: 0.00749149466512825\n",
      "Epoch 13/50 - Error: 0.007151170007690523\n",
      "Epoch 14/50 - Error: 0.0068513753058377655\n",
      "Epoch 15/50 - Error: 0.006579689314487496\n",
      "Epoch 16/50 - Error: 0.0063330798433987555\n",
      "Epoch 17/50 - Error: 0.006110914374501388\n",
      "Epoch 18/50 - Error: 0.005901538202647225\n",
      "Epoch 19/50 - Error: 0.005710694583677819\n",
      "Epoch 20/50 - Error: 0.005530456693187848\n",
      "Epoch 21/50 - Error: 0.005361789838703905\n",
      "Epoch 22/50 - Error: 0.0052076078155167075\n",
      "Epoch 23/50 - Error: 0.00506161039391688\n",
      "Epoch 24/50 - Error: 0.00492332783342815\n",
      "Epoch 25/50 - Error: 0.0047983101314184205\n",
      "Epoch 26/50 - Error: 0.004674793526629783\n",
      "Epoch 27/50 - Error: 0.004562274544967232\n",
      "Epoch 28/50 - Error: 0.004453605224782833\n",
      "Epoch 29/50 - Error: 0.004349811960798437\n",
      "Epoch 30/50 - Error: 0.0042514014382438\n",
      "Epoch 31/50 - Error: 0.004153177573034192\n",
      "Epoch 32/50 - Error: 0.004059959118959822\n",
      "Epoch 33/50 - Error: 0.003971047984789483\n",
      "Epoch 34/50 - Error: 0.0038808877039312423\n",
      "Epoch 35/50 - Error: 0.003800381567921747\n",
      "Epoch 36/50 - Error: 0.003719859434279845\n",
      "Epoch 37/50 - Error: 0.0036371179612441854\n",
      "Epoch 38/50 - Error: 0.0035618135263755734\n",
      "Epoch 39/50 - Error: 0.0034882607027601894\n",
      "Epoch 40/50 - Error: 0.0034201431871029547\n",
      "Epoch 41/50 - Error: 0.0033535220227777925\n",
      "Epoch 42/50 - Error: 0.0032859403577167037\n",
      "Epoch 43/50 - Error: 0.0032221983408489874\n",
      "Epoch 44/50 - Error: 0.0031553261758685944\n",
      "Epoch 45/50 - Error: 0.003093216007306315\n",
      "Epoch 46/50 - Error: 0.003031761107224497\n",
      "Epoch 47/50 - Error: 0.0029736413238842497\n",
      "Epoch 48/50 - Error: 0.0029154529052963637\n",
      "Epoch 49/50 - Error: 0.0028607737119348375\n",
      "Epoch 50/50 - Error: 0.0028080246072775417\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    error = 0\n",
    "    for i in range(len(x_train)):\n",
    "        input = x_train[i].reshape(-1, 1)\n",
    "        for layer in network:\n",
    "            input = layer.forward(input)\n",
    "        error += mse(y_train[i].reshape(-1, 1), input)\n",
    "        output_gradient = mse_prime(y_train[i].reshape(-1, 1), input)\n",
    "        for layer in reversed(network):\n",
    "            output_gradient = layer.backward(output_gradient, learning_rate)\n",
    "    error /= len(x_train)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error after training: 0.018601656944059738\n",
      "Accuracy: 88.88888888888889%\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "correct_pred = 0\n",
    "dataset_len = 0\n",
    "for i in range(len(x_test)):\n",
    "    dataset_len += 1\n",
    "    input = x_test[i].reshape(-1, 1)\n",
    "    for layer in network:\n",
    "        input = layer.forward(input)\n",
    "    predicted = np.argmax(input)\n",
    "    target = np.argmax(y_test[i])\n",
    "    if predicted == target:\n",
    "        correct_pred += 1\n",
    "    test_error += mse(y_test[i].reshape(-1, 1), input)\n",
    "test_error /= len(x_test)\n",
    "print(f\"Test Error after training: {test_error}\")\n",
    "accuracy = correct_pred / dataset_len * 100\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
